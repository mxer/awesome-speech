# awesome-speech
this is a treasure-house of speech

## 目录
* [语音识别（ASR,STT）](#1)
  * [page](#1.1)
  * [open source library/toolbox/code](#1.2)
  * [corpus/dataset](#1.3)
  * [教程（Tutorial）](#1.4)
* [语音合成（Speech Synthesis,TTS）](#2)
  * [page](#2.1)
  * [open source library/toolbox/code](#2.2)
  * [corpus/dataset](#2.3)
  * [教程（Tutorial）](#2.4)
* [声纹识别（Speaker Recognition）](#3)
  * [page](#3.1)
  * [open source library/toolbox/code](#3.2)
  * [corpus/dataset](#3.3)
  * [教程（Tutorial）](#3.4)
* [对话系统（Dialogue Systems）](#4)
  * [page](#4.1)
  * [open source library/toolbox/code](#4.2)
  * [corpus/dataset](#4.3)
  * [教程（Tutorial）](#4.4)
* [前端（front end）](#5)
  * [Speech Processing](#5.1)
  * [Audio I/O](#5.2)
  * [Sound Source Separation](#5.3)
  * [Feature Extraction](#5.4)
  * [VAD](#5.5)
* [resource](#6)
  * [code/tool/data](#6.1)
  * [Tutorial](#6.2)
  * [paper](#6.3)
* [pages](#7)

## <h2 id="1">语音识别</h2>
 ### <h3 id="1.2">open source library/toolbox/code</h3>
 #### HTK
* http://htk.eng.cam.ac.uk/download.shtml)
 #### Kaldi:
* https://github.com/kaldi-asr/kaldi
 #### py-kaldi-asr
* https://github.com/gooofy/py-kaldi-asr
 #### Dan's DNN implementation:
* http://kaldi-asr.org/doc/dnn2.html
 #### pytorch-kaldi
* https://github.com/mravanelli/pytorch-kaldi/
 #### kaldi-lstm
* https://github.com/dophist/kaldi-lstm
 #### keras-kaldi
* https://github.com/dspavankumar/keras-kaldi
 #### Kaldi+PDNN
* https://github.com/yajiemiao/kaldipdnn
 #### kaldi-ivector
* https://github.com/idiap/kaldi-ivector
 #### tfkaldi
* https://github.com/vrenkens/tfkaldi
 #### kaldi 在线中文识别系统搭建
* https://blog.csdn.net/shichaog/article/details/73655628
 #### CSLT-Sparse-DNN-Toolkit
* https://github.com/wyq730/CSLT-Sparse-DNN-Toolkit
 #### featxtra
* https://github.com/mvansegbroeck/featxtra
 #### Sphinx
* https://cmusphinx.github.io/
* https://github.com/cmusphinx
* https://github.com/cmusphinx/pocketsphinx
 #### OpenFst
* http://www.openfst.org/twiki/bin/view/FST/WebHome
 #### MIT Spoken Language Systems
* https://groups.csail.mit.edu/sls/downloads/
 #### Julius
* http://julius.osdn.jp/en_index.php
* https://github.com/julius-speech/julius
 #### Bavieca
* http://www.bavieca.org/
 #### Simon 
* https://simon.kde.org/
 #### SRILM
* https://www.sri.com/engage/products-solutions/sri-language-modeling-toolkit
* https://github.com/njsmith/pysrilm
 #### ISIP
* https://www.isip.piconepress.com/projects/speech/
 #### VoxForge
* http://www.voxforge.org/home
 #### MIT Finite-State Transducer (FST) Toolkit
* http://groups.csail.mit.edu/sls/downloads/
 #### MIT Language Modeling (MITLM) Toolkit
* http://groups.csail.mit.edu/sls/downloads/
 #### OpenGrm
* http://www.openfst.org/twiki/bin/view/GRM/WebHome
 #### RNNLM
* http://www.fit.vutbr.cz/~imikolov/rnnlm/
 #### SpeechRecognition
* https://github.com/Uberi/speech_recognition
 #### SpeechPy
* https://github.com/astorfi/speechpy
 #### Aalto
* https://github.com/aalto-speech/AaltoASR
 #### google-cloud-speech
* https://pypi.org/project/google-cloud-speech/
 #### apiai
https://pypi.org/project/apiai/
 #### wit
* https://github.com/wit-ai/pywit
 #### Nabu
* https://github.com/vrenkens/nabu
 #### asr-study
* https://github.com/igormq/asr-study
 #### dejavu
* https://github.com/worldveil/dejavu
 #### uSpeech
* https://github.com/arjo129/uSpeech
 #### Juicer
* https://github.com/idiap/juicer
 #### dragonfly
* https://github.com/t4ngo/dragonfly
 #### SPTK
* http://sp-tk.sourceforge.net/
 #### Speech Recognition Grammar Specification
* https://www.w3.org/TR/speech-grammar/
 #### Automatic_Speech_Recognition
* https://github.com/zzw922cn/Automatic_Speech_Recognition
 #### speech-to-text-wavenet
* https://github.com/buriburisuri/speech-to-text-wavenet
 #### tensorflow-speech-recognition
* https://github.com/pannous/tensorflow-speech-recognition
 #### tensorflow_speech_recognition_demo
* https://github.com/llSourcell/tensorflow_speech_recognition_demo
 #### AVSR-Deep-Speech
* https://github.com/pandeydivesh15/AVSR-Deep-Speech
 #### TTS and ASR
* https://github.com/roboticslab-uc3m/speech
 #### CTC + Tensorflow Example for ASR
* https://github.com/igormq/ctc_tensorflow_example
 #### speechT
* https://github.com/timediv/speechT

 ### <h3 id="1.3">dataset</h3>
 #### The CMU Pronouncing Dictionary
* http://www.speech.cs.cmu.edu/cgi-bin/cmudict
 #### TIMIT
* https://catalog.ldc.upenn.edu/LDC93S1


## <h2 id="2">语音合成</h2>
### <h3 id="2.2">open source library/toolbox</h3>
 #### WORLD
* https://github.com/mmorise/World
 #### HTS
* http://hts.sp.nitech.ac.jp/
* http://hts-engine.sourceforge.net/
 #### Tacotron
* https://github.com/Kyubyong/tacotron
* https://github.com/Kyubyong/expressive_tacotron
* https://github.com/keithito/tacotron
* https://github.com/GSByeon/multi-speaker-tacotron-tensorflow
* https://github.com/r9y9/tacotron_pytorch
 #### Tacotron2
* https://github.com/riverphoenix/tacotron2
* https://github.com/A-Jacobson/tacotron2
* https://github.com/selap91/Tacotron2
* https://github.com/LGizkde/Tacotron2_Tao_Shujie
* https://github.com/rlawns1016/Tacotron2
* https://github.com/CapstoneInha/Tacotron2-rehearsal
 #### Merlin
* https://github.com/CSTR-Edinburgh/merlin
 #### mozilla TTS
* https://github.com/mozilla/TTS
 #### Flite
* http://www.speech.cs.cmu.edu/flite/
* https://github.com/festvox/flite
 #### Speect
* http://speect.sourceforge.net/
 #### Festival
* https://github.com/festvox/festival
 #### eSpeak
* http://espeak.sourceforge.net/
 #### nnmnkwii
* https://github.com/r9y9/nnmnkwii
 #### Ossian
* https://github.com/CSTR-Edinburgh/Ossian
 #### Neural_Network_Voices
* https://github.com/llSourcell/Neural_Network_Voices
 #### pggan-pytorch
* https://github.com/deepsound-project/pggan-pytorch
 #### cainteoir-engine
* https://github.com/rhdunn/cainteoir-engine
 #### loop
* https://github.com/facebookresearch/loop
 #### nnmnkwii
* https://github.com/r9y9/nnmnkwii
 #### TTS and ASR
* https://github.com/roboticslab-uc3m/speech
 #### musa_tts
* https://github.com/santi-pdp/musa_tts
 #### marytts(JAVA)
* https://github.com/marytts/marytts
 #### deep-voice-conversion
* https://github.com/andabi/deep-voice-conversion


## <h2 id="3">声纹识别</h2>
 ### <h3 id="3.2">open source library/toolbox</h3>
 #### speaker-recognition-py3
* https://github.com/crouchred/speaker-recognition-py3
 #### openVP
* https://github.com/dake/openVP
* https://github.com/swshon?tab=repositories

## <h2 id="4">对话系统</h3>
 ### <h2 id="4.2">open source library/toolbox</h3>
 #### PyDial
* http://www.camdial.org/pydial/
 #### alex
* https://github.com/UFAL-DSG/alex
 #### ROS 语音交互系统
* https://github.com/hntea/ros-speech
 #### 结合ROS框架的中文语音交互系统 
* https://github.com/hntea/speech-system-zh

## <h2 id="5">前端</h2>
 ### <h3 id="5.1">Speech Processing</h3>
 #### madmom
* https://github.com/CPJKU/madmom
 #### pydub
* https://github.com/jiaaro/pydub
 #### kapre: Keras Audio Preprocessors
* https://github.com/keunwoochoi/kapre
 #### BTK
* http://distantspeechrecognition.sourceforge.net/
 #### Signal-Processing
* https://github.com/mathEnthusaistCodes/Signal-Processing
 #### pyroomacoustics
* https://github.com/LCAV/pyroomacoustics
 #### librosa
* https://github.com/librosa/librosa
 #### VOICEBOX
* http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html
 #### mir_eval
* https://github.com/craffel/mir_eval
 #### Pitch Detection
* http://note.sonots.com/SciSoftware/Pitch.html
 #### TFTB
* http://tftb.nongnu.org/
 #### maracas
* https://github.com/jfsantos/maracas
 #### SRMRpy
* https://github.com/jfsantos/SRMRpy
 #### Audio super resolution using NN
* https://github.com/kuleshov/audio-super-res
 #### RNN training for noise reduction in robust asr
* https://github.com/amaas/rnn-speech-denoising
 #### RNN for audio noise reduction
* https://github.com/xiph/rnnoise
 #### muda
* https://github.com/bmcfee/muda

 ### <h3 id="5.2">Audio I/O</h3>
 #### PortAudio
* http://www.portaudio.com/
 #### audiolab
* https://github.com/cournape/audiolab
 #### Digital Speech Decoder
* https://github.com/szechyjs/dsd
 #### audioread
* https://github.com/beetbox/audioread
 #### audacity.py
* https://github.com/davidavdav/audacity.py

 ### <h3 id="5.3">Sound Source Separation</h3>
 #### HARK
* https://www.hark.jp/wiki.cgi?page=HARK+Installation+Instructions
 #### Deep RNN for Source Separation
* https://github.com/posenhuang/deeplearningsourceseparation
 #### nussl
* https://github.com/interactiveaudiolab/nussl

 ### <h3 id="5.4">Feature Extraction</h3>
 #### openSMILE
* https://audeering.com/technology/opensmile/
 #### veles.sound_feature_extraction
* https://github.com/Samsung/veles.sound_feature_extraction
 #### py_bank
* https://github.com/wil-j-wil/py_bank
 #### AuditoryFilterbanks
* https://github.com/jfsantos/AuditoryFilterbanks


## <h2 id="6">资源</h2>
 ###<h3 id="6.1">code/tool/data</h3>
 ### cmusphinx
* https://github.com/cmusphinx
 #### julius-speech
* https://github.com/julius-speech
 #### OpenSLR
* http://www.openslr.org/
 #### List of speech recognition software
* https://en.wikipedia.org/wiki/List_of_speech_recognition_software
 #### VERBIO
* http://www.verbio.com/webverbiotm/html/productes.php?id=2
 #### Speech at CMU Web Page
* http://www.speech.cs.cmu.edu/
 #### CMU Robust Speech Group
* http://www.cs.cmu.edu/~robust/code.html
 #### Speech Software at CMU
* http://www.speech.cs.cmu.edu/hephaestus.html
 #### Aalto Speech Research
* https://github.com/aalto-speech
 #### CMU Festvox Project
* https://github.com/festvox?tab=repositories
* http://www.festvox.org/
 #### CSTR
* http://www.cstr.ed.ac.uk/research/
 #### Xiph
* https://github.com/xiph
 #### Brno University of Technology Speech Processing Group
* http://speech.fit.vutbr.cz/software
 #### Sparse Representation & Dictionary Learning Algorithms with Applications in Denoising, Separation, Localisation and Tracking
* http://personal.ee.surrey.ac.uk/Personal/W.Wang/codes.html
 #### Audacity
* https://www.audacityteam.org/
 #### beetbox
* https://github.com/beetbox
* https://github.com/andabi?tab=repositories
 #### CAQE
* https://github.com/interactiveaudiolab/CAQE
 
 ### <h3 id="6.3">paper</h3>
* https://arxiv.org/search/?query=speech&searchtype=all&source=header
* https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers


## <h2 id="7">主页</h2>
 #### cmusphinx
* https://github.com/cmusphinx
 #### CMU Language Technologies Institute
* https://www.lti.cs.cmu.edu/work
 #### MIT Spoken Language Systems
* https://groups.csail.mit.edu/sls/downloads/
 #### Brno University of Technology Speech Processing Group
* http://speech.fit.vutbr.cz/software
