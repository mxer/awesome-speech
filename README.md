# awesome-speech
this is a treasure-house of speech

## 目录
* [语音识别（ASR,STT）](#1)
  * [page](#1.1)
  * [open source library/toolbox](#1.2)
  * [corpus/dataset](#1.3)
  * [教程（Tutorial）](#1.4)
* [语音合成（Speech Synthesis,TTS）](#2)
  * [page](#2.1)
  * [open source library/toolbox](#2.2)
  * [corpus/dataset](#2.3)
  * [教程（Tutorial）](#2.4)
* [声纹识别（Speaker Recognition）](#3)
  * [page](#3.1)
  * [open source library/toolbox](#3.2)
  * [corpus/dataset](#3.3)
  * [教程（Tutorial）](#3.4)
* [对话系统（Dialogue Systems）](#4)
  * [page](#4.1)
  * [open source library/toolbox](#4.2)
  * [corpus/dataset](#4.3)
  * [教程（Tutorial）](#4.4)
* [前端（front end）](#5)
  * [Speech Processing](#5.1)
  * [Audio I/O](#5.2)
  * [Source Separation](#5.3)
  * [Feature Extraction](#5.4)
* [resource](#6)
* [pages](#7)

## <h2 id="1">语音识别</h2>
### <h3 id="1.2">open source library/toolbox</h3>
### [HTK](http://htk.eng.cam.ac.uk/download.shtml)
### Kaldi:
* https://github.com/kaldi-asr/kaldi
  #### py-kaldi-asr
* https://github.com/gooofy/py-kaldi-asr
  #### Dan's DNN implementation:
* http://kaldi-asr.org/doc/dnn2.html
  #### pytorch-kaldi
* https://github.com/mravanelli/pytorch-kaldi/
  #### kaldi-lstm
* https://github.com/dophist/kaldi-lstm
  #### keras-kaldi
* https://github.com/dspavankumar/keras-kaldi
  #### Kaldi+PDNN
* https://github.com/yajiemiao/kaldipdnn
  #### kaldi-ivector
* https://github.com/idiap/kaldi-ivector
  #### CSLT-Sparse-DNN-Toolkit
* https://github.com/wyq730/CSLT-Sparse-DNN-Toolkit
  #### kaldi 在线中文识别系统搭建
* https://blog.csdn.net/shichaog/article/details/73655628
### Sphinx
* https://cmusphinx.github.io/
* https://github.com/cmusphinx
* https://pypi.org/project/pocketsphinx/
### OpenFst
* http://www.openfst.org/twiki/bin/view/FST/WebHome
### MIT Spoken Language Systems
* https://groups.csail.mit.edu/sls/downloads/
### Julius
* http://julius.osdn.jp/en_index.php
* https://github.com/julius-speech/julius
### Bavieca
* http://www.bavieca.org/
### Simon 
* https://simon.kde.org/
### SRILM
* https://www.sri.com/engage/products-solutions/sri-language-modeling-toolkit
* https://github.com/njsmith/pysrilm
### ISIP
* https://www.isip.piconepress.com/projects/speech/
###  MIT Finite-State Transducer (FST) Toolkit
* http://groups.csail.mit.edu/sls/downloads/
### MIT Language Modeling (MITLM) Toolkit
* http://groups.csail.mit.edu/sls/downloads/
### OpenGrm
* http://www.openfst.org/twiki/bin/view/GRM/WebHome
### SpeechRecognition
* https://github.com/Uberi/speech_recognition
### SpeechPy
* https://github.com/astorfi/speechpy
### Aalto
* https://github.com/aalto-speech/AaltoASR
### google-cloud-speech
* https://pypi.org/project/google-cloud-speech/
### apiai
https://pypi.org/project/apiai/
### wit
* https://pypi.org/project/wit/
### dejavu
* https://github.com/worldveil/dejavu
### uSpeech
* https://github.com/arjo129/uSpeech
### Juicer
* https://github.com/idiap/juicer
### dragonfly
* https://github.com/t4ngo/dragonfly
### SPTK
* http://sp-tk.sourceforge.net/
### Speech Recognition Grammar Specification
* https://www.w3.org/TR/speech-grammar/
### Automatic_Speech_Recognition
* https://github.com/zzw922cn/Automatic_Speech_Recognition
### speech-to-text-wavenet
* https://github.com/buriburisuri/speech-to-text-wavenet
### tensorflow-speech-recognition
* https://github.com/pannous/tensorflow-speech-recognition
### tensorflow_speech_recognition_demo
* https://github.com/llSourcell/tensorflow_speech_recognition_demo
### AVSR-Deep-Speech
* https://github.com/pandeydivesh15/AVSR-Deep-Speech


## <h2 id="2">语音合成</h2>
### <h3 id="2.2">open source library/toolbox</h3>
### WORLD
* https://github.com/mmorise/World
### HTS
* http://hts.sp.nitech.ac.jp/
* http://hts-engine.sourceforge.net/
### Tacotron2
* https://github.com/riverphoenix/tacotron2
* https://github.com/A-Jacobson/tacotron2
* https://github.com/selap91/Tacotron2
* https://github.com/LGizkde/Tacotron2_Tao_Shujie
* https://github.com/rlawns1016/Tacotron2
* https://github.com/CapstoneInha/Tacotron2-rehearsal
### Merlin
* https://github.com/CSTR-Edinburgh/merlin
### mozilla TTS
* https://github.com/mozilla/TTS
### Flite
* http://www.speech.cs.cmu.edu/flite/
### Speect
* http://speect.sourceforge.net/
### Festival
* https://github.com/festvox/festival
### eSpeak
* http://espeak.sourceforge.net/
### nnmnkwii
* https://github.com/r9y9/nnmnkwii
### Ossian
* https://github.com/CSTR-Edinburgh/Ossian
### Neural_Network_Voices
* https://github.com/llSourcell/Neural_Network_Voices
### pggan-pytorch
* https://github.com/deepsound-project/pggan-pytorch
### cainteoir-engine
* https://github.com/rhdunn/cainteoir-engine
### marytts(JAVA)
* https://github.com/marytts/marytts

## <h6 id="3">声纹识别</h6>
### <h7 id="3.2">open source library/toolbox</h7>
### speaker-recognition-py3
* https://github.com/crouchred/speaker-recognition-py3

## <h8 id="4">对话系统</h8>
### <h9 id="4.2">open source library/toolbox</h9>
### PyDial
* http://www.camdial.org/pydial/
### alex
* https://github.com/UFAL-DSG/alex

## <h10 id="5">前端</h10>
### <h11 id="5.2">open source library/toolbox</h11>
### madmom
* https://github.com/CPJKU/madmom
### pydub
* https://github.com/jiaaro/pydub
### PortAudio
* http://www.portaudio.com/
### audiolab
* https://github.com/cournape/audiolab
### BTK
http://distantspeechrecognition.sourceforge.net/
### HARK
* https://www.hark.jp/wiki.cgi?page=HARK+Installation+Instructions
### openSMILE(Feature Extractor)
* https://audeering.com/technology/opensmile/
### VOICEBOX
* http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html
### featxtra
* https://github.com/mvansegbroeck/featxtra
### Signal-Processing
* https://github.com/mathEnthusaistCodes/Signal-Processing
### kapre: Keras Audio Preprocessors
* https://github.com/keunwoochoi/kapre
### pyroomacoustics
* https://github.com/LCAV/pyroomacoustics
### audio-super-res
* https://github.com/kuleshov/audio-super-res
### librosa
* https://github.com/librosa/librosa
### Pitch Detection
* http://note.sonots.com/SciSoftware/Pitch.html
### TFTB
* http://tftb.nongnu.org/
### Digital Speech Decoder
* https://github.com/szechyjs/dsd
### audacity.py
* https://github.com/davidavdav/audacity.py
### maracas
* https://github.com/jfsantos/maracas



## <h12 id="6">资源</h12>
### cmusphinx
* https://github.com/cmusphinx
### julius-speech
* https://github.com/julius-speech
### OpenSLR
* http://www.openslr.org/
### List of speech recognition software
* https://en.wikipedia.org/wiki/List_of_speech_recognition_software
### VERBIO
* http://www.verbio.com/webverbiotm/html/productes.php?id=2
### Speech at CMU Web Page
* http://www.speech.cs.cmu.edu/
### CMU Robust Speech Group
* http://www.cs.cmu.edu/~robust/code.html
### Speech Software at CMU
* http://www.speech.cs.cmu.edu/hephaestus.html
### Aalto Speech Research
* https://github.com/aalto-speech
### CMU Festvox Project
* https://github.com/festvox?tab=repositories
* http://www.festvox.org/
### CSTR
* http://www.cstr.ed.ac.uk/research/
### Sparse Representation & Dictionary Learning Algorithms with Applications in Denoising, Separation, Localisation and Tracking
* http://personal.ee.surrey.ac.uk/Personal/W.Wang/codes.html
### Audacity
* https://www.audacityteam.org/

## <h13 id="7">资源</h13>
### cmusphinx
* https://github.com/cmusphinx
### CMU Language Technologies Institute
* https://www.lti.cs.cmu.edu/work
### MIT Spoken Language Systems
* https://groups.csail.mit.edu/sls/downloads/
